{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee4e579b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144000, 35)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "files = glob.glob(\"feature-data/*_feature.csv\")\n",
    "df_all = pd.concat([pd.read_csv(f) for f in files], ignore_index=True)\n",
    "print(df_all.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90c86a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File: feature-data\\01M_1_feature.csv\n",
      "  Label 0: 7176 samples\n",
      "  Label 1: 24 samples\n",
      "\n",
      "File: feature-data\\01M_2_feature.csv\n",
      "  Label 0: 7144 samples\n",
      "  Label 1: 56 samples\n",
      "\n",
      "File: feature-data\\02F_1_feature.csv\n",
      "  Label 0: 7165 samples\n",
      "  Label 1: 35 samples\n",
      "\n",
      "File: feature-data\\02F_2_feature.csv\n",
      "  Label 0: 7171 samples\n",
      "  Label 1: 29 samples\n",
      "\n",
      "File: feature-data\\03F_1_feature.csv\n",
      "  Label 0: 7115 samples\n",
      "  Label 1: 85 samples\n",
      "\n",
      "File: feature-data\\03F_2_feature.csv\n",
      "  Label 0: 7108 samples\n",
      "  Label 1: 92 samples\n",
      "\n",
      "File: feature-data\\04M_1_feature.csv\n",
      "  Label 0: 7164 samples\n",
      "  Label 1: 36 samples\n",
      "\n",
      "File: feature-data\\04M_2_feature.csv\n",
      "  Label 0: 7155 samples\n",
      "  Label 1: 45 samples\n",
      "\n",
      "File: feature-data\\05M_1_feature.csv\n",
      "  Label 0: 7176 samples\n",
      "  Label 1: 24 samples\n",
      "\n",
      "File: feature-data\\05M_2_feature.csv\n",
      "  Label 0: 7162 samples\n",
      "  Label 1: 38 samples\n",
      "\n",
      "File: feature-data\\06M_1_feature.csv\n",
      "  Label 0: 7165 samples\n",
      "  Label 1: 35 samples\n",
      "\n",
      "File: feature-data\\06M_2_feature.csv\n",
      "  Label 0: 7183 samples\n",
      "  Label 1: 17 samples\n",
      "\n",
      "File: feature-data\\07F_1_feature.csv\n",
      "  Label 0: 7111 samples\n",
      "  Label 1: 89 samples\n",
      "\n",
      "File: feature-data\\07F_2_feature.csv\n",
      "  Label 0: 7038 samples\n",
      "  Label 1: 162 samples\n",
      "\n",
      "File: feature-data\\08M_1_feature.csv\n",
      "  Label 0: 7196 samples\n",
      "  Label 1: 4 samples\n",
      "\n",
      "File: feature-data\\08M_2_feature.csv\n",
      "  Label 0: 7193 samples\n",
      "  Label 1: 7 samples\n",
      "\n",
      "File: feature-data\\09M_1_feature.csv\n",
      "  Label 0: 7199 samples\n",
      "  Label 1: 1 samples\n",
      "\n",
      "File: feature-data\\09M_2_feature.csv\n",
      "  Label 0: 7196 samples\n",
      "  Label 1: 4 samples\n",
      "\n",
      "File: feature-data\\10M_1_feature.csv\n",
      "  Label 0: 7198 samples\n",
      "  Label 1: 2 samples\n",
      "\n",
      "File: feature-data\\10M_2_feature.csv\n",
      "  Label 0: 7193 samples\n",
      "  Label 1: 7 samples\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your CSV files\n",
    "files = glob.glob(\"feature-data/*_feature.csv\")\n",
    "\n",
    "# Loop through each file and print label counts\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    # You can change 'avg_heart_rate' to the actual label column if different (e.g., 'label' or 'drowsy')\n",
    "    label_col = 'label'\n",
    "    \n",
    "    if label_col in df.columns:\n",
    "        counts = df[label_col].value_counts().sort_index()\n",
    "        print(f\"\\nFile: {file}\")\n",
    "        for label, count in counts.items():\n",
    "            print(f\"  Label {label}: {count} samples\")\n",
    "    else:\n",
    "        print(f\"\\nFile: {file} — Column '{label_col}' not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69a527b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a392d906",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e669abf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min avg_heart_rate: 0\n",
      "Max avg_heart_rate: 360\n",
      "\n",
      "Sample count in each heart rate window (10 bpm steps):\n",
      "(0.0, 10.0]: 0 samples\n",
      "(10.0, 20.0]: 0 samples\n",
      "(20.0, 30.0]: 0 samples\n",
      "(30.0, 40.0]: 0 samples\n",
      "(40.0, 50.0]: 0 samples\n",
      "(50.0, 60.0]: 102346 samples\n",
      "(60.0, 70.0]: 0 samples\n",
      "(70.0, 80.0]: 0 samples\n",
      "(80.0, 90.0]: 0 samples\n",
      "(90.0, 100.0]: 0 samples\n",
      "(100.0, 110.0]: 0 samples\n",
      "(110.0, 120.0]: 36815 samples\n",
      "(120.0, 130.0]: 0 samples\n",
      "(130.0, 140.0]: 0 samples\n",
      "(140.0, 150.0]: 0 samples\n",
      "(150.0, 160.0]: 0 samples\n",
      "(160.0, 170.0]: 0 samples\n",
      "(170.0, 180.0]: 3250 samples\n",
      "(180.0, 190.0]: 0 samples\n",
      "(190.0, 200.0]: 0 samples\n",
      "(200.0, 210.0]: 0 samples\n",
      "(210.0, 220.0]: 0 samples\n",
      "(220.0, 230.0]: 0 samples\n",
      "(230.0, 240.0]: 1062 samples\n",
      "(240.0, 250.0]: 0 samples\n",
      "(250.0, 260.0]: 0 samples\n",
      "(260.0, 270.0]: 0 samples\n",
      "(270.0, 280.0]: 0 samples\n",
      "(280.0, 290.0]: 0 samples\n",
      "(290.0, 300.0]: 449 samples\n",
      "(300.0, 310.0]: 0 samples\n",
      "(310.0, 320.0]: 0 samples\n",
      "(320.0, 330.0]: 0 samples\n",
      "(330.0, 340.0]: 0 samples\n",
      "(340.0, 350.0]: 0 samples\n",
      "(350.0, 360.0]: 31 samples\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load all the CSV files\n",
    "files = glob.glob(\"feature-data/*_feature.csv\")\n",
    "df_all = pd.concat([pd.read_csv(f) for f in files], ignore_index=True)\n",
    "\n",
    "# Ensure the column exists\n",
    "if 'avg_heart_rate' not in df_all.columns:\n",
    "    raise ValueError(\"Column 'avg_heart_rate' not found in the dataset.\")\n",
    "\n",
    "# Get min and max\n",
    "min_hr = df_all['avg_heart_rate'].min()\n",
    "max_hr = df_all['avg_heart_rate'].max()\n",
    "\n",
    "print(f\"Min avg_heart_rate: {min_hr}\")\n",
    "print(f\"Max avg_heart_rate: {max_hr}\")\n",
    "\n",
    "# Define bins (windows of 10)\n",
    "bins = np.arange(start=np.floor(min_hr), stop=np.ceil(max_hr) + 10, step=10)\n",
    "\n",
    "# Use pandas cut to assign each value to a bin\n",
    "df_all['hr_bin'] = pd.cut(df_all['avg_heart_rate'], bins=bins)\n",
    "\n",
    "# Count samples per bin\n",
    "bin_counts = df_all['hr_bin'].value_counts().sort_index()\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nSample count in each heart rate window (10 bpm steps):\")\n",
    "for bin_range, count in bin_counts.items():\n",
    "    print(f\"{bin_range}: {count} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73fd1ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eac5c401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data loaded: (144000, 36)\n",
      "(143954, 34) (115163, 34) (28791, 34)\n",
      "(143954,) (115163,) (28791,)\n",
      "\n",
      "=== Logistic Regression ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\ILP-PROJECT\\envfirst\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\User\\Desktop\\ILP-PROJECT\\envfirst\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\User\\Desktop\\ILP-PROJECT\\envfirst\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9945    1.0000    0.9972     28633\n",
      "           1     0.0000    0.0000    0.0000       158\n",
      "\n",
      "    accuracy                         0.9945     28791\n",
      "   macro avg     0.4973    0.5000    0.4986     28791\n",
      "weighted avg     0.9891    0.9945    0.9918     28791\n",
      "\n",
      "Confusion Matrix:\n",
      " [[28633     0]\n",
      " [  158     0]]\n",
      "\n",
      "=== K-Nearest Neighbors ===\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9946    1.0000    0.9973     28633\n",
      "           1     0.6667    0.0127    0.0248       158\n",
      "\n",
      "    accuracy                         0.9945     28791\n",
      "   macro avg     0.8306    0.5063    0.5111     28791\n",
      "weighted avg     0.9928    0.9945    0.9919     28791\n",
      "\n",
      "Confusion Matrix:\n",
      " [[28632     1]\n",
      " [  156     2]]\n",
      "\n",
      "=== Decision Tree ===\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9946    0.9938    0.9942     28633\n",
      "           1     0.0221    0.0253    0.0236       158\n",
      "\n",
      "    accuracy                         0.9885     28791\n",
      "   macro avg     0.5084    0.5096    0.5089     28791\n",
      "weighted avg     0.9893    0.9885    0.9889     28791\n",
      "\n",
      "Confusion Matrix:\n",
      " [[28456   177]\n",
      " [  154     4]]\n",
      "\n",
      "=== Random Forest ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\ILP-PROJECT\\envfirst\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\User\\Desktop\\ILP-PROJECT\\envfirst\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\User\\Desktop\\ILP-PROJECT\\envfirst\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9945    1.0000    0.9972     28633\n",
      "           1     0.0000    0.0000    0.0000       158\n",
      "\n",
      "    accuracy                         0.9945     28791\n",
      "   macro avg     0.4973    0.5000    0.4986     28791\n",
      "weighted avg     0.9891    0.9945    0.9918     28791\n",
      "\n",
      "Confusion Matrix:\n",
      " [[28633     0]\n",
      " [  158     0]]\n",
      "\n",
      "=== Support Vector Machine ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\ILP-PROJECT\\envfirst\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\User\\Desktop\\ILP-PROJECT\\envfirst\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\User\\Desktop\\ILP-PROJECT\\envfirst\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9945    1.0000    0.9972     28633\n",
      "           1     0.0000    0.0000    0.0000       158\n",
      "\n",
      "    accuracy                         0.9945     28791\n",
      "   macro avg     0.4973    0.5000    0.4986     28791\n",
      "weighted avg     0.9891    0.9945    0.9918     28791\n",
      "\n",
      "Confusion Matrix:\n",
      " [[28633     0]\n",
      " [  158     0]]\n",
      "\n",
      "=== Gradient Boosting ===\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9945    0.9995    0.9970     28633\n",
      "           1     0.0000    0.0000    0.0000       158\n",
      "\n",
      "    accuracy                         0.9940     28791\n",
      "   macro avg     0.4973    0.4997    0.4985     28791\n",
      "weighted avg     0.9891    0.9940    0.9915     28791\n",
      "\n",
      "Confusion Matrix:\n",
      " [[28618    15]\n",
      " [  158     0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Load all feature CSV files\n",
    "# -----------------------------\n",
    "DATA_PATH = \"feature-data\"\n",
    "feature_files = [f for f in os.listdir(DATA_PATH) if f.endswith(\"_feature.csv\")]\n",
    "\n",
    "dfs = []\n",
    "for f in feature_files:\n",
    "    df = pd.read_csv(os.path.join(DATA_PATH, f))\n",
    "    df[\"source_file\"] = f  # keep track of origin\n",
    "    dfs.append(df)\n",
    "\n",
    "data = pd.concat(dfs, ignore_index=True)\n",
    "print(\"✅ Data loaded:\", data.shape)\n",
    "\n",
    "# -----------------------------\n",
    "# Handle NaN / Inf\n",
    "# -----------------------------\n",
    "data = data.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "# -----------------------------\n",
    "# Split features and labels\n",
    "# -----------------------------\n",
    "X = data.drop(columns=[\"label\", \"source_file\"])\n",
    "y = data[\"label\"]\n",
    "\n",
    "# Standardize features (important for SVM, KNN, Logistic)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# -----------------------------\n",
    "# Train-test split\n",
    "# -----------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(X_scaled.shape,X_train.shape,X_test.shape)\n",
    "print(y.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Define classifiers\n",
    "# -----------------------------\n",
    "classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Support Vector Machine\": SVC(random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# Train & Evaluate\n",
    "# -----------------------------\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7df76ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: [114529    634]\n",
      "After SMOTE : [114529 114529]\n",
      "\n",
      "=== Logistic Regression ===\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9974    0.7481    0.8550     28633\n",
      "           1     0.0139    0.6456    0.0273       158\n",
      "\n",
      "    accuracy                         0.7476     28791\n",
      "   macro avg     0.5057    0.6968    0.4411     28791\n",
      "weighted avg     0.9920    0.7476    0.8504     28791\n",
      "\n",
      "Confusion Matrix:\n",
      " [[21421  7212]\n",
      " [   56   102]]\n",
      "\n",
      "=== K-Nearest Neighbors ===\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9953    0.9434    0.9687     28633\n",
      "           1     0.0188    0.1962    0.0343       158\n",
      "\n",
      "    accuracy                         0.9393     28791\n",
      "   macro avg     0.5070    0.5698    0.5015     28791\n",
      "weighted avg     0.9900    0.9393    0.9635     28791\n",
      "\n",
      "Confusion Matrix:\n",
      " [[27012  1621]\n",
      " [  127    31]]\n",
      "\n",
      "=== Decision Tree ===\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9950    0.9727    0.9837     28633\n",
      "           1     0.0225    0.1139    0.0376       158\n",
      "\n",
      "    accuracy                         0.9680     28791\n",
      "   macro avg     0.5087    0.5433    0.5106     28791\n",
      "weighted avg     0.9897    0.9680    0.9785     28791\n",
      "\n",
      "Confusion Matrix:\n",
      " [[27851   782]\n",
      " [  140    18]]\n",
      "\n",
      "=== Random Forest ===\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9948    0.9951    0.9950     28633\n",
      "           1     0.0544    0.0506    0.0525       158\n",
      "\n",
      "    accuracy                         0.9900     28791\n",
      "   macro avg     0.5246    0.5229    0.5237     28791\n",
      "weighted avg     0.9896    0.9900    0.9898     28791\n",
      "\n",
      "Confusion Matrix:\n",
      " [[28494   139]\n",
      " [  150     8]]\n",
      "\n",
      "=== Support Vector Machine ===\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9968    0.8387    0.9110     28633\n",
      "           1     0.0174    0.5190    0.0338       158\n",
      "\n",
      "    accuracy                         0.8370     28791\n",
      "   macro avg     0.5071    0.6789    0.4724     28791\n",
      "weighted avg     0.9915    0.8370    0.9062     28791\n",
      "\n",
      "Confusion Matrix:\n",
      " [[24015  4618]\n",
      " [   76    82]]\n",
      "\n",
      "=== Gradient Boosting ===\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9972    0.8699    0.9292     28633\n",
      "           1     0.0231    0.5570    0.0443       158\n",
      "\n",
      "    accuracy                         0.8682     28791\n",
      "   macro avg     0.5101    0.7134    0.4868     28791\n",
      "weighted avg     0.9919    0.8682    0.9243     28791\n",
      "\n",
      "Confusion Matrix:\n",
      " [[24907  3726]\n",
      " [   70    88]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# SMOTE Oversampling on train set only\n",
    "smote = SMOTE(random_state=42, sampling_strategy='auto')\n",
    "X_res, y_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Before SMOTE:\", np.bincount(y_train))\n",
    "print(\"After SMOTE :\", np.bincount(y_res))\n",
    "\n",
    "# Updated classifiers with class weights\n",
    "classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced'),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42, class_weight='balanced'),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'),\n",
    "    \"Support Vector Machine\": SVC(random_state=42, class_weight='balanced'),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    clf.fit(X_res, y_res)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76fad5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e45bad7",
   "metadata": {},
   "source": [
    "### **For 5s Window CSV FILES same Logic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62e1ebd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28800, 35)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "files = glob.glob(\"feature-data-5second/*_feature5s.csv\")\n",
    "df_all = pd.concat([pd.read_csv(f) for f in files], ignore_index=True)\n",
    "print(df_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4fa0a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File: feature-data-5second\\01M_1_feature5s.csv\n",
      "  Label 0: 1416 samples\n",
      "  Label 1: 24 samples\n",
      "\n",
      "File: feature-data-5second\\01M_2_feature5s.csv\n",
      "  Label 0: 1384 samples\n",
      "  Label 1: 56 samples\n",
      "\n",
      "File: feature-data-5second\\02F_1_feature5s.csv\n",
      "  Label 0: 1406 samples\n",
      "  Label 1: 34 samples\n",
      "\n",
      "File: feature-data-5second\\02F_2_feature5s.csv\n",
      "  Label 0: 1411 samples\n",
      "  Label 1: 29 samples\n",
      "\n",
      "File: feature-data-5second\\03F_1_feature5s.csv\n",
      "  Label 0: 1355 samples\n",
      "  Label 1: 85 samples\n",
      "\n",
      "File: feature-data-5second\\03F_2_feature5s.csv\n",
      "  Label 0: 1349 samples\n",
      "  Label 1: 91 samples\n",
      "\n",
      "File: feature-data-5second\\04M_1_feature5s.csv\n",
      "  Label 0: 1404 samples\n",
      "  Label 1: 36 samples\n",
      "\n",
      "File: feature-data-5second\\04M_2_feature5s.csv\n",
      "  Label 0: 1395 samples\n",
      "  Label 1: 45 samples\n",
      "\n",
      "File: feature-data-5second\\05M_1_feature5s.csv\n",
      "  Label 0: 1417 samples\n",
      "  Label 1: 23 samples\n",
      "\n",
      "File: feature-data-5second\\05M_2_feature5s.csv\n",
      "  Label 0: 1403 samples\n",
      "  Label 1: 37 samples\n",
      "\n",
      "File: feature-data-5second\\06M_1_feature5s.csv\n",
      "  Label 0: 1407 samples\n",
      "  Label 1: 33 samples\n",
      "\n",
      "File: feature-data-5second\\06M_2_feature5s.csv\n",
      "  Label 0: 1423 samples\n",
      "  Label 1: 17 samples\n",
      "\n",
      "File: feature-data-5second\\07F_1_feature5s.csv\n",
      "  Label 0: 1351 samples\n",
      "  Label 1: 89 samples\n",
      "\n",
      "File: feature-data-5second\\07F_2_feature5s.csv\n",
      "  Label 0: 1279 samples\n",
      "  Label 1: 161 samples\n",
      "\n",
      "File: feature-data-5second\\08M_1_feature5s.csv\n",
      "  Label 0: 1436 samples\n",
      "  Label 1: 4 samples\n",
      "\n",
      "File: feature-data-5second\\08M_2_feature5s.csv\n",
      "  Label 0: 1433 samples\n",
      "  Label 1: 7 samples\n",
      "\n",
      "File: feature-data-5second\\09M_1_feature5s.csv\n",
      "  Label 0: 1439 samples\n",
      "  Label 1: 1 samples\n",
      "\n",
      "File: feature-data-5second\\09M_2_feature5s.csv\n",
      "  Label 0: 1436 samples\n",
      "  Label 1: 4 samples\n",
      "\n",
      "File: feature-data-5second\\10M_1_feature5s.csv\n",
      "  Label 0: 1438 samples\n",
      "  Label 1: 2 samples\n",
      "\n",
      "File: feature-data-5second\\10M_2_feature5s.csv\n",
      "  Label 0: 1433 samples\n",
      "  Label 1: 7 samples\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your CSV files\n",
    "files = glob.glob(\"feature-data-5second/*_feature5s.csv\")\n",
    "\n",
    "# Loop through each file and print label counts\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    # You can change 'avg_heart_rate' to the actual label column if different (e.g., 'label' or 'drowsy')\n",
    "    label_col = 'label'\n",
    "    \n",
    "    if label_col in df.columns:\n",
    "        counts = df[label_col].value_counts().sort_index()\n",
    "        print(f\"\\nFile: {file}\")\n",
    "        for label, count in counts.items():\n",
    "            print(f\"  Label {label}: {count} samples\")\n",
    "    else:\n",
    "        print(f\"\\nFile: {file} — Column '{label_col}' not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "863aa33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min avg_heart_rate: 24.0\n",
      "Max avg_heart_rate: 288.0\n",
      "\n",
      "Sample count in each heart rate window (10 bpm steps):\n",
      "(24.0, 34.0]: 0 samples\n",
      "(34.0, 44.0]: 16 samples\n",
      "(44.0, 54.0]: 871 samples\n",
      "(54.0, 64.0]: 6677 samples\n",
      "(64.0, 74.0]: 11337 samples\n",
      "(74.0, 84.0]: 6144 samples\n",
      "(84.0, 94.0]: 0 samples\n",
      "(94.0, 104.0]: 1583 samples\n",
      "(104.0, 114.0]: 857 samples\n",
      "(114.0, 124.0]: 532 samples\n",
      "(124.0, 134.0]: 323 samples\n",
      "(134.0, 144.0]: 206 samples\n",
      "(144.0, 154.0]: 0 samples\n",
      "(154.0, 164.0]: 110 samples\n",
      "(164.0, 174.0]: 48 samples\n",
      "(174.0, 184.0]: 24 samples\n",
      "(184.0, 194.0]: 11 samples\n",
      "(194.0, 204.0]: 5 samples\n",
      "(204.0, 214.0]: 0 samples\n",
      "(214.0, 224.0]: 1 samples\n",
      "(224.0, 234.0]: 3 samples\n",
      "(234.0, 244.0]: 6 samples\n",
      "(244.0, 254.0]: 16 samples\n",
      "(254.0, 264.0]: 16 samples\n",
      "(264.0, 274.0]: 0 samples\n",
      "(274.0, 284.0]: 11 samples\n",
      "(284.0, 294.0]: 2 samples\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load all the CSV files\n",
    "files = glob.glob(\"feature-data-5second/*_feature5s.csv\")\n",
    "df_all = pd.concat([pd.read_csv(f) for f in files], ignore_index=True)\n",
    "\n",
    "# Ensure the column exists\n",
    "if 'avg_heart_rate' not in df_all.columns:\n",
    "    raise ValueError(\"Column 'avg_heart_rate' not found in the dataset.\")\n",
    "\n",
    "# Get min and max\n",
    "min_hr = df_all['avg_heart_rate'].min()\n",
    "max_hr = df_all['avg_heart_rate'].max()\n",
    "\n",
    "print(f\"Min avg_heart_rate: {min_hr}\")\n",
    "print(f\"Max avg_heart_rate: {max_hr}\")\n",
    "\n",
    "# Define bins (windows of 10)\n",
    "bins = np.arange(start=np.floor(min_hr), stop=np.ceil(max_hr) + 10, step=10)\n",
    "\n",
    "# Use pandas cut to assign each value to a bin\n",
    "df_all['hr_bin'] = pd.cut(df_all['avg_heart_rate'], bins=bins)\n",
    "\n",
    "# Count samples per bin\n",
    "bin_counts = df_all['hr_bin'].value_counts().sort_index()\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nSample count in each heart rate window (10 bpm steps):\")\n",
    "for bin_range, count in bin_counts.items():\n",
    "    print(f\"{bin_range}: {count} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9840410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data loaded: (28800, 36)\n",
      "(28800, 34) (23040, 34) (5760, 34)\n",
      "(28800,) (23040,) (5760,)\n",
      "Before SMOTE: [22412   628]\n",
      "After SMOTE : [22412 22412]\n",
      "\n",
      "=== Logistic Regression ===\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9892    0.7660    0.8634      5603\n",
      "           1     0.0774    0.7006    0.1394       157\n",
      "\n",
      "    accuracy                         0.7642      5760\n",
      "   macro avg     0.5333    0.7333    0.5014      5760\n",
      "weighted avg     0.9643    0.7642    0.8437      5760\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4292 1311]\n",
      " [  47  110]]\n",
      "\n",
      "=== K-Nearest Neighbors ===\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9818    0.8738    0.9246      5603\n",
      "           1     0.0854    0.4204    0.1419       157\n",
      "\n",
      "    accuracy                         0.8615      5760\n",
      "   macro avg     0.5336    0.6471    0.5333      5760\n",
      "weighted avg     0.9573    0.8615    0.9033      5760\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4896  707]\n",
      " [  91   66]]\n",
      "\n",
      "=== Decision Tree ===\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9801    0.9315    0.9552      5603\n",
      "           1     0.1172    0.3248    0.1723       157\n",
      "\n",
      "    accuracy                         0.9149      5760\n",
      "   macro avg     0.5487    0.6282    0.5637      5760\n",
      "weighted avg     0.9566    0.9149    0.9338      5760\n",
      "\n",
      "Confusion Matrix:\n",
      " [[5219  384]\n",
      " [ 106   51]]\n",
      "\n",
      "=== Random Forest ===\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9797    0.9807    0.9802      5603\n",
      "           1     0.2848    0.2739    0.2792       157\n",
      "\n",
      "    accuracy                         0.9615      5760\n",
      "   macro avg     0.6322    0.6273    0.6297      5760\n",
      "weighted avg     0.9607    0.9615    0.9611      5760\n",
      "\n",
      "Confusion Matrix:\n",
      " [[5495  108]\n",
      " [ 114   43]]\n",
      "\n",
      "=== Support Vector Machine ===\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9870    0.8281    0.9006      5603\n",
      "           1     0.0907    0.6115    0.1579       157\n",
      "\n",
      "    accuracy                         0.8222      5760\n",
      "   macro avg     0.5388    0.7198    0.5293      5760\n",
      "weighted avg     0.9626    0.8222    0.8804      5760\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4640  963]\n",
      " [  61   96]]\n",
      "\n",
      "=== Gradient Boosting ===\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9854    0.8560    0.9161      5603\n",
      "           1     0.0963    0.5478    0.1638       157\n",
      "\n",
      "    accuracy                         0.8476      5760\n",
      "   macro avg     0.5409    0.7019    0.5400      5760\n",
      "weighted avg     0.9612    0.8476    0.8956      5760\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4796  807]\n",
      " [  71   86]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Load all feature CSV files\n",
    "# -----------------------------\n",
    "DATA_PATH = \"feature-data-5second\"\n",
    "feature_files = [f for f in os.listdir(DATA_PATH) if f.endswith(\"_feature5s.csv\")]\n",
    "\n",
    "dfs = []\n",
    "for f in feature_files:\n",
    "    df = pd.read_csv(os.path.join(DATA_PATH, f))\n",
    "    df[\"source_file\"] = f  # keep track of origin\n",
    "    dfs.append(df)\n",
    "\n",
    "data = pd.concat(dfs, ignore_index=True)\n",
    "print(\"✅ Data loaded:\", data.shape)\n",
    "\n",
    "# -----------------------------\n",
    "# Handle NaN / Inf\n",
    "# -----------------------------\n",
    "data = data.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "# -----------------------------\n",
    "# Split features and labels\n",
    "# -----------------------------\n",
    "X = data.drop(columns=[\"label\", \"source_file\"])\n",
    "y = data[\"label\"]\n",
    "\n",
    "# Standardize features (important for SVM, KNN, Logistic)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# -----------------------------\n",
    "# Train-test split\n",
    "# -----------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(X_scaled.shape,X_train.shape,X_test.shape)\n",
    "print(y.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# SMOTE Oversampling on train set only\n",
    "smote = SMOTE(random_state=42, sampling_strategy='auto')\n",
    "X_res, y_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Before SMOTE:\", np.bincount(y_train))\n",
    "print(\"After SMOTE :\", np.bincount(y_res))\n",
    "\n",
    "# Updated classifiers with class weights\n",
    "classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced'),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42, class_weight='balanced'),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'),\n",
    "    \"Support Vector Machine\": SVC(random_state=42, class_weight='balanced'),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    clf.fit(X_res, y_res)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45ea020",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db71142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443ec962",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3f6d56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8c7fbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9731e71d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2617be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a5061d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5abd61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2353284",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envfirst",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
